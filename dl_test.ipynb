{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pygrinder import mcar\n",
    "from pypots.data import load_specific_dataset\n",
    "from pypots.imputation import SAITS\n",
    "from pypots.utils.metrics import calc_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-24 17:28:17 [INFO]: Loading the dataset physionet_2012 with TSDB (https://github.com/WenjieDu/Time_Series_Data_Beans)...\n",
      "2024-01-24 17:28:17 [INFO]: Starting preprocessing physionet_2012...\n",
      "2024-01-24 17:28:17 [INFO]: You're using dataset physionet_2012, please cite it properly in your work. You can find its reference information at the below link: \n",
      "https://github.com/WenjieDu/TSDB/tree/main/dataset_profiles/physionet_2012\n",
      "2024-01-24 17:28:17 [INFO]: Start downloading...\n",
      "2024-01-24 17:28:27 [INFO]: Successfully downloaded data to /tmp/tmpnmn6wozu/set-a.tar.gz\n",
      "2024-01-24 17:28:28 [INFO]: Successfully extracted data to /home/nick/.tsdb/physionet_2012\n",
      "2024-01-24 17:28:37 [INFO]: Successfully downloaded data to /tmp/tmpzkqudr2g/set-b.tar.gz\n",
      "2024-01-24 17:28:38 [INFO]: Successfully extracted data to /home/nick/.tsdb/physionet_2012\n",
      "2024-01-24 17:28:46 [INFO]: Successfully downloaded data to /tmp/tmp34salsl5/set-c.tar.gz\n",
      "2024-01-24 17:28:46 [INFO]: Successfully extracted data to /home/nick/.tsdb/physionet_2012\n",
      "2024-01-24 17:28:47 [INFO]: Successfully downloaded data to /home/nick/.tsdb/physionet_2012/Outcomes-a.txt\n",
      "2024-01-24 17:28:48 [INFO]: Successfully downloaded data to /home/nick/.tsdb/physionet_2012/Outcomes-b.txt\n",
      "2024-01-24 17:28:50 [INFO]: Successfully downloaded data to /home/nick/.tsdb/physionet_2012/Outcomes-c.txt\n",
      "2024-01-24 17:28:52 [WARNING]: Ignore 141264, because its len==1, having no time series data\n",
      "2024-01-24 17:28:56 [WARNING]: Ignore 140501, because its len==1, having no time series data\n",
      "2024-01-24 17:29:00 [WARNING]: Ignore 140936, because its len==1, having no time series data\n",
      "2024-01-24 17:29:11 [WARNING]: Ignore 143656, because its len==1, having no time series data\n",
      "2024-01-24 17:29:13 [WARNING]: Ignore 142998, because its len==1, having no time series data\n",
      "2024-01-24 17:29:17 [WARNING]: Ignore 142731, because its len==1, having no time series data\n",
      "2024-01-24 17:29:17 [WARNING]: Ignore 150649, because its len==1, having no time series data\n",
      "2024-01-24 17:29:18 [WARNING]: Ignore 150309, because its len==1, having no time series data\n",
      "2024-01-24 17:29:21 [WARNING]: Ignore 145611, because its len==1, having no time series data\n",
      "2024-01-24 17:29:26 [WARNING]: Ignore 147514, because its len==1, having no time series data\n",
      "2024-01-24 17:29:37 [WARNING]: Ignore 155655, because its len==1, having no time series data\n",
      "2024-01-24 17:29:44 [WARNING]: Ignore 156254, because its len==1, having no time series data\n",
      "2024-01-24 17:29:57 [INFO]: Successfully saved to /home/nick/.tsdb/physionet_2012/physionet_2012_cache.pkl\n",
      "2024-01-24 17:29:57 [INFO]: Loaded successfully!\n",
      "2024-01-24 17:30:20 [INFO]: No given device, using default device: cpu\n",
      "2024-01-24 17:30:20 [WARNING]: ‚ÄºÔ∏è saving_path not given. Model files and tensorboard file will not be saved.\n",
      "2024-01-24 17:30:20 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 1,378,358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11988, 48, 37)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-24 17:30:56 [INFO]: Epoch 001 - training loss: 0.6672\n",
      "2024-01-24 17:31:33 [INFO]: Epoch 002 - training loss: 0.4842\n",
      "2024-01-24 17:32:10 [INFO]: Epoch 003 - training loss: 0.4279\n",
      "2024-01-24 17:32:46 [INFO]: Epoch 004 - training loss: 0.3901\n",
      "2024-01-24 17:33:20 [INFO]: Epoch 005 - training loss: 0.3717\n",
      "2024-01-24 17:33:59 [INFO]: Epoch 006 - training loss: 0.3565\n",
      "2024-01-24 17:34:36 [INFO]: Epoch 007 - training loss: 0.3470\n",
      "2024-01-24 17:35:14 [INFO]: Epoch 008 - training loss: 0.3388\n",
      "2024-01-24 17:35:55 [INFO]: Epoch 009 - training loss: 0.3314\n",
      "2024-01-24 17:36:37 [INFO]: Epoch 010 - training loss: 0.3261\n",
      "2024-01-24 17:36:37 [INFO]: Finished training.\n",
      "2024-01-24 17:36:37 [WARNING]: üö®DeprecationWarning: The method impute is deprecated. Please use `predict` instead.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Data preprocessing. Tedious, but PyPOTS can help.\n",
    "data = load_specific_dataset('physionet_2012')  # PyPOTS will automatically download and extract it.\n",
    "X = data['X']\n",
    "num_samples = len(X['RecordID'].unique())\n",
    "X = X.drop(['RecordID', 'Time'], axis = 1)\n",
    "X = StandardScaler().fit_transform(X.to_numpy())\n",
    "X = X.reshape(num_samples, 48, -1)\n",
    "X_ori = X  # keep X_ori for validation\n",
    "X = mcar(X, 0.1)  # randomly hold out 10% observed values as ground truth\n",
    "dataset = {\"X\": X}  # X for model input\n",
    "print(X.shape)  # (11988, 48, 37), 11988 samples, 48 time steps, 37 features\n",
    "\n",
    "# Model training. This is PyPOTS showtime.\n",
    "saits = SAITS(n_steps=48, n_features=37, n_layers=2, d_model=256, d_inner=128, n_heads=4, d_k=64, d_v=64, dropout=0.1, epochs=10)\n",
    "# Here I use the whole dataset as the training set because ground truth is not visible to the model, you can also split it into train/val/test sets\n",
    "saits.fit(dataset)\n",
    "imputation = saits.impute(dataset)  # impute the originally-missing values and artificially-missing values\n",
    "indicating_mask = np.isnan(X) ^ np.isnan(X_ori)  # indicating mask for imputation error calculation\n",
    "mae = calc_mae(imputation, np.nan_to_num(X_ori), indicating_mask)  # calculate mean absolute error on the ground truth (artificially-missing values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X':         RecordID  Time  ALP  ALT  AST  Albumin  BUN  Bilirubin  Cholesterol  \\\n",
       " 0         132539   0.0  NaN  NaN  NaN      NaN  NaN        NaN          NaN   \n",
       " 1         132539   1.0  NaN  NaN  NaN      NaN  NaN        NaN          NaN   \n",
       " 2         132539   2.0  NaN  NaN  NaN      NaN  NaN        NaN          NaN   \n",
       " 3         132539   3.0  NaN  NaN  NaN      NaN  NaN        NaN          NaN   \n",
       " 4         132539   4.0  NaN  NaN  NaN      NaN  NaN        NaN          NaN   \n",
       " ...          ...   ...  ...  ...  ...      ...  ...        ...          ...   \n",
       " 575419    163037  43.0  NaN  NaN  NaN      NaN  NaN        NaN          NaN   \n",
       " 575420    163037  44.0  NaN  NaN  NaN      NaN  NaN        NaN          NaN   \n",
       " 575421    163037  45.0  NaN  NaN  NaN      NaN  NaN        NaN          NaN   \n",
       " 575422    163037  46.0  NaN  NaN  NaN      NaN  NaN        NaN          NaN   \n",
       " 575423    163037  47.0  NaN  NaN  NaN      NaN  NaN        NaN          NaN   \n",
       " \n",
       "         Creatinine  ...  RespRate  SaO2  SysABP   Temp  TroponinI  TroponinT  \\\n",
       " 0              NaN  ...      19.0   NaN     NaN  35.35        NaN        NaN   \n",
       " 1              NaN  ...      18.0   NaN     NaN    NaN        NaN        NaN   \n",
       " 2              NaN  ...      19.0   NaN     NaN    NaN        NaN        NaN   \n",
       " 3              NaN  ...      20.0   NaN     NaN  37.80        NaN        NaN   \n",
       " 4              NaN  ...      20.0   NaN     NaN    NaN        NaN        NaN   \n",
       " ...            ...  ...       ...   ...     ...    ...        ...        ...   \n",
       " 575419         NaN  ...       NaN   NaN   122.0    NaN        NaN        NaN   \n",
       " 575420         NaN  ...       NaN   NaN     NaN    NaN        NaN        NaN   \n",
       " 575421         NaN  ...       NaN   NaN   147.0  37.30        NaN        NaN   \n",
       " 575422         NaN  ...       NaN   NaN    90.0    NaN        NaN        NaN   \n",
       " 575423         NaN  ...       NaN   NaN    99.0    NaN        NaN        NaN   \n",
       " \n",
       "         Urine  WBC  Weight  pH  \n",
       " 0       480.0  NaN    -1.0 NaN  \n",
       " 1        30.0  NaN     NaN NaN  \n",
       " 2       170.0  NaN     NaN NaN  \n",
       " 3        60.0  NaN     NaN NaN  \n",
       " 4         NaN  NaN     NaN NaN  \n",
       " ...       ...  ...     ...  ..  \n",
       " 575419   60.0  NaN     NaN NaN  \n",
       " 575420    NaN  NaN     NaN NaN  \n",
       " 575421   50.0  NaN     NaN NaN  \n",
       " 575422    NaN  NaN     NaN NaN  \n",
       " 575423   30.0  NaN     NaN NaN  \n",
       " \n",
       " [575424 rows x 39 columns],\n",
       " 'y':           In-hospital_death\n",
       " RecordID                   \n",
       " 139169                    1\n",
       " 139644                    0\n",
       " 139068                    0\n",
       " 136040                    0\n",
       " 136292                    0\n",
       " ...                     ...\n",
       " 162054                    0\n",
       " 154077                    0\n",
       " 156131                    0\n",
       " 155844                    0\n",
       " 159365                    0\n",
       " \n",
       " [11988 rows x 1 columns],\n",
       " 'ICUType':           ICUType\n",
       " RecordID         \n",
       " 132539        4.0\n",
       " 132540        2.0\n",
       " 132541        3.0\n",
       " 132543        3.0\n",
       " 132545        3.0\n",
       " ...           ...\n",
       " 163029        4.0\n",
       " 163033        3.0\n",
       " 163034        4.0\n",
       " 163035        1.0\n",
       " 163037        1.0\n",
       " \n",
       " [11988 rows x 1 columns]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hydro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
