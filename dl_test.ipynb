{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-29 17:50:11 [ERROR]: ‚ùå No module named 'torch_geometric'\n",
      "Note torch_geometric is missing, please install it with 'pip install torch_geometric torch_scatter torch_sparse' or 'conda install -c pyg pyg pytorch-scatter pytorch-sparse'\n",
      "2024-01-29 17:50:11 [ERROR]: ‚ùå name 'MessagePassing' is not defined\n",
      "Note torch_geometric is missing, please install it with 'pip install torch_geometric torch_scatter torch_sparse' or 'conda install -c pyg pyg pytorch-scatter pytorch-sparse'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pygrinder import mcar\n",
    "from pypots.data import load_specific_dataset\n",
    "from pypots.imputation import SAITS\n",
    "from pypots.utils.metrics import calc_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2089025536\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.get_device_properties(0).total_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-29 17:50:21 [INFO]: Loading the dataset physionet_2012 with TSDB (https://github.com/WenjieDu/Time_Series_Data_Beans)...\n",
      "2024-01-29 17:50:21 [INFO]: Starting preprocessing physionet_2012...\n",
      "2024-01-29 17:50:21 [INFO]: You're using dataset physionet_2012, please cite it properly in your work. You can find its reference information at the below link: \n",
      "https://github.com/WenjieDu/TSDB/tree/main/dataset_profiles/physionet_2012\n",
      "2024-01-29 17:50:21 [INFO]: Dataset physionet_2012 has already been downloaded. Processing directly...\n",
      "2024-01-29 17:50:21 [INFO]: Dataset physionet_2012 has already been cached. Loading from cache directly...\n",
      "2024-01-29 17:50:21 [INFO]: Loaded successfully!\n",
      "2024-01-29 17:50:44 [INFO]: Using the given device: cuda\n",
      "2024-01-29 17:50:44 [WARNING]: ‚ÄºÔ∏è saving_path not given. Model files and tensorboard file will not be saved.\n",
      "2024-01-29 17:50:44 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 1,378,358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11988, 48, 37)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-29 17:51:01 [INFO]: Epoch 001 - training loss: 0.6667\n",
      "2024-01-29 17:51:16 [INFO]: Epoch 002 - training loss: 0.4856\n",
      "2024-01-29 17:51:32 [INFO]: Epoch 003 - training loss: 0.4281\n",
      "2024-01-29 17:51:47 [INFO]: Epoch 004 - training loss: 0.3882\n",
      "2024-01-29 17:52:03 [INFO]: Epoch 005 - training loss: 0.3702\n",
      "2024-01-29 17:52:19 [INFO]: Epoch 006 - training loss: 0.3564\n",
      "2024-01-29 17:52:34 [INFO]: Epoch 007 - training loss: 0.3481\n",
      "2024-01-29 17:52:50 [INFO]: Epoch 008 - training loss: 0.3388\n",
      "2024-01-29 17:53:05 [INFO]: Epoch 009 - training loss: 0.3337\n",
      "2024-01-29 17:53:21 [INFO]: Epoch 010 - training loss: 0.3300\n",
      "2024-01-29 17:53:21 [INFO]: Finished training.\n",
      "2024-01-29 17:53:21 [WARNING]: üö®DeprecationWarning: The method impute is deprecated. Please use `predict` instead.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Data preprocessing. Tedious, but PyPOTS can help.\n",
    "data = load_specific_dataset('physionet_2012')  # PyPOTS will automatically download and extract it.\n",
    "X = data['X']\n",
    "num_samples = len(X['RecordID'].unique())\n",
    "X = X.drop(['RecordID', 'Time'], axis = 1)\n",
    "X = StandardScaler().fit_transform(X.to_numpy())\n",
    "X = X.reshape(num_samples, 48, -1)\n",
    "X_ori = X  # keep X_ori for validation\n",
    "X = mcar(X, 0.1)  # randomly hold out 10% observed values as ground truth\n",
    "dataset = {\"X\": X}  # X for model input\n",
    "print(X.shape)  # (11988, 48, 37), 11988 samples, 48 time steps, 37 features\n",
    "\n",
    "# Model training. This is PyPOTS showtime.\n",
    "saits = SAITS(n_steps=48, n_features=37, n_layers=2, d_model=256, d_inner=128, n_heads=4, d_k=64, d_v=64, dropout=0.1, epochs=10, device='cuda')\n",
    "# Here I use the whole dataset as the training set because ground truth is not visible to the model, you can also split it into train/val/test sets\n",
    "saits.fit(dataset)\n",
    "imputation = saits.impute(dataset)  # impute the originally-missing values and artificially-missing values\n",
    "indicating_mask = np.isnan(X) ^ np.isnan(X_ori)  # indicating mask for imputation error calculation\n",
    "mae = calc_mae(imputation, np.nan_to_num(X_ori), indicating_mask)  # calculate mean absolute error on the ground truth (artificially-missing values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22807315689144705"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hydro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
